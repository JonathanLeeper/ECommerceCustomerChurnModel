{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0f74dbc-0f83-4e29-a7ea-2784baa34f66",
   "metadata": {},
   "source": [
    "* Jonathan Leeper\n",
    "* Project 3 - Customer Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07424954-1e12-48fc-8e77-223e5257ec8f",
   "metadata": {},
   "source": [
    "# E-Commerce Customer Churn Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e22f1b-e34f-4ca0-bc40-6729daa31068",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81f6e40-cd09-48a8-af07-c4dfba4c1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import numpy as np\n",
    "df = pd.read_excel(\"E Commerce Dataset.xlsx\", sheet_name=\"E Comm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e136a5-a92b-4af8-9667-6e8ce0548323",
   "metadata": {},
   "source": [
    "## Step 1: Import Dataset, Choose Churn as Target, and begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157fff99-def7-4ff0-bc2f-8eaa5fbc17c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Churn', axis=1)  # Features\n",
    "y = df['Churn']  # Target\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b50b9a-017c-4739-959f-5e02d155350d",
   "metadata": {},
   "source": [
    "## Step 2: Create a Preprocessor for our models to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a95e6e-0f84-4edf-b52a-fe9fde199ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_cols),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))  # Handle unknown categories\n",
    "        ]), categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ec169-14ef-4d31-8c2f-702ea4449c06",
   "metadata": {},
   "source": [
    "## Step 3: Function for training & Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0edf53d-bc88-4c27-a00f-93dc68e96f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate models\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    # Create a pipeline with preprocessing and model\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Fit the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate model\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6bde97-e120-4357-9906-13652cf95914",
   "metadata": {},
   "source": [
    "## Step 4: Training each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b3a9943-d4d8-422a-a543-92d4af11d825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "Confusion Matrix:\n",
      "[[926  15]\n",
      " [ 80 105]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       941\n",
      "           1       0.88      0.57      0.69       185\n",
      "\n",
      "    accuracy                           0.92      1126\n",
      "   macro avg       0.90      0.78      0.82      1126\n",
      "weighted avg       0.91      0.92      0.91      1126\n",
      "\n",
      "==================================================\n",
      "Model: DecisionTreeClassifier\n",
      "Confusion Matrix:\n",
      "[[919  22]\n",
      " [ 27 158]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       941\n",
      "           1       0.88      0.85      0.87       185\n",
      "\n",
      "    accuracy                           0.96      1126\n",
      "   macro avg       0.92      0.92      0.92      1126\n",
      "weighted avg       0.96      0.96      0.96      1126\n",
      "\n",
      "==================================================\n",
      "Model: RandomForestClassifier\n",
      "Confusion Matrix:\n",
      "[[939   2]\n",
      " [ 39 146]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       941\n",
      "           1       0.99      0.79      0.88       185\n",
      "\n",
      "    accuracy                           0.96      1126\n",
      "   macro avg       0.97      0.89      0.93      1126\n",
      "weighted avg       0.96      0.96      0.96      1126\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Models to compare\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    train_and_evaluate(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b9f9c-06d4-4946-81df-3e59b553cbfe",
   "metadata": {},
   "source": [
    "## Step 5: Using Hyperparameters to find the best scores & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b8d78a-9649-4ece-8cea-dad96601661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grids for Decision Tree and Random Forest\n",
    "param_grid_dt = {\n",
    "    'model__max_depth': [5, 10, 15, 20],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'model__n_estimators': [50, 100, 150],\n",
    "    'model__max_depth': [5, 10, 15],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 5],\n",
    "    'model__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create pipelines for Decision Tree and Random Forest with preprocessing\n",
    "pipeline_dt = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32383847-7871-4960-b7c1-7eb7a9075ca8",
   "metadata": {},
   "source": [
    "## Step 6: Using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa9e49b-0fcd-46e0-b34d-621c3ca1da4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "Best parameters for Decision Tree: {'model__max_depth': 15, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "Best score for Decision Tree: 0.9251823899371068\n",
      "Best parameters for Random Forest: {'model__max_depth': 15, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
      "Best score for Random Forest: 0.9429419163891971\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV for Decision Tree\n",
    "grid_search_dt = GridSearchCV(pipeline_dt, param_grid_dt, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV for Random Forest\n",
    "grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and scores\n",
    "print(\"Best parameters for Decision Tree:\", grid_search_dt.best_params_)\n",
    "print(\"Best score for Decision Tree:\", grid_search_dt.best_score_)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)\n",
    "print(\"Best score for Random Forest:\", grid_search_rf.best_score_)\n",
    "\n",
    "# Evaluate best models on the test set\n",
    "best_dt_model = grid_search_dt.best_estimator_\n",
    "best_rf_model = grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e50563-a226-4925-84dd-d794259cc5f6",
   "metadata": {},
   "source": [
    "## Step 7: Using Test Set For Each of the selected best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4c8ae57-4d6c-4ba5-9146-a43cccf2a1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       941\n",
      "           1       0.87      0.84      0.86       185\n",
      "\n",
      "    accuracy                           0.95      1126\n",
      "   macro avg       0.92      0.91      0.91      1126\n",
      "weighted avg       0.95      0.95      0.95      1126\n",
      "\n",
      "\n",
      "Random Forest - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       941\n",
      "           1       0.99      0.74      0.84       185\n",
      "\n",
      "    accuracy                           0.95      1126\n",
      "   macro avg       0.97      0.87      0.91      1126\n",
      "weighted avg       0.96      0.95      0.95      1126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test set evaluation for Decision Tree\n",
    "y_pred_dt = best_dt_model.predict(X_test)\n",
    "print(\"\\nDecision Tree - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Test set evaluation for Random Forest\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "print(\"\\nRandom Forest - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b67aedf-c64e-4aa2-ab7c-54d32a92b102",
   "metadata": {},
   "source": [
    "**Although the choice between the two models is tough, as recall is a better score for decision tree**, Precision on deciding if Customer Churn will happen is more important in this experiment. In this case, I decided Random Forest is a better model for accurate future predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd32c99-d65e-470c-9dd9-988f42c190e1",
   "metadata": {},
   "source": [
    "## Step 8: Saving the model as a PKL file, for accurate future predictions without needing to train data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3ddf18b-2e49-4b01-a606-d8b8f5cb60c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_rf_model, 'CustomerChurnRF.pkl')\n",
    "\n",
    "loaded_model = joblib.load('CustomerChurnRF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f798aa2-e0cf-4dd2-b3a2-d68339a3ed02",
   "metadata": {},
   "source": [
    "## Final Product: Predicting Customer Churn on New Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "988b7b7c-eb57-47a7-8b6d-7645f1441123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (0 = Not churned, 1 = Churned): [0]\n"
     ]
    }
   ],
   "source": [
    "# Column names (use the same ones from your training dataset)\n",
    "columns = ['CustomerID', 'Tenure', 'PreferredLoginDevice', 'CityTier', \n",
    "           'WarehouseToHome', 'PreferredPaymentMode', 'Gender', \n",
    "           'HourSpendOnApp', 'NumberOfDeviceRegistered', 'PreferedOrderCat', \n",
    "           'SatisfactionScore', 'MaritalStatus', 'NumberOfAddress', 'Complain', \n",
    "           'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount', \n",
    "           'DaySinceLastOrder', 'CashbackAmount']\n",
    "\n",
    "# Example of a new customer\n",
    "new_customer_data = np.array([[10001,   # CustomerID (irrelevant)\n",
    "                               3,       # Tenure\n",
    "                               0,       # PreferredLoginDevice (0 = Mobile, 1 = Phone)\n",
    "                               2,       # CityTier\n",
    "                               10,      # WarehouseToHome\n",
    "                               3,       # PreferredPaymentMode (coded as an integer, same as login device & gender)\n",
    "                               1,       # Gender (0 = Female, 1 = Male)\n",
    "                               2,       # HourSpendOnApp\n",
    "                               2,       # NumberOfDeviceRegistered\n",
    "                               1,       # PreferedOrderCat (coded, same as the other integers)\n",
    "                               3,       # SatisfactionScore\n",
    "                               1,       # MaritalStatus (coded)\n",
    "                               5,       # NumberOfAddress\n",
    "                               0,       # Complain\n",
    "                               5,       # OrderAmountHikeFromlastYear\n",
    "                               0,       # CouponUsed\n",
    "                               3,       # OrderCount\n",
    "                               10,      # DaySinceLastOrder\n",
    "                               135]])  # CashbackAmount (numeric)\n",
    "\n",
    "# Create a DataFrame with the new data, using the column names from the training data\n",
    "new_data_df = pd.DataFrame(new_customer_data, columns=columns)\n",
    "\n",
    "# Now you can use the transformed data for prediction\n",
    "prediction = loaded_model.predict(new_data_df)\n",
    "\n",
    "print(f\"Prediction (0 = Not churned, 1 = Churned): {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f3b30-7445-4418-9901-4c4217d15db1",
   "metadata": {},
   "source": [
    "As you can see above, With our new customer data, we were able to determine that this customer will not churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b08fac-8dee-49ef-8ae2-b6f3dfd0a40d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
